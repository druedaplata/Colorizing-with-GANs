{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorizar imágenes con GANS\n",
    "### https://arxiv.org/pdf/1803.05400.pdf\n",
    "#### Diego Rueda\n",
    "\n",
    "Este es un problema de traducción de imagen a imagen que mapea una entrada multidimensional a una salida multidimensional. La red tambien debe entregar información de color para cada pixel en la imagen en escala de grises. \n",
    "\n",
    "El modelo base sigue una red convolucional de extremo a extremo, donde las redes fully connected son reemplazadas por capas convolucionales que incluyen remuestreo (upsampling) en lugar de agrupación (pooling).\n",
    "Esta idea es basada en redes encoder-decoder donde la entrada es reducida de tamaño prograsivamente y luego el proceso es revertido usando una serie de capas expansivas para reconstruir la entrada.\n",
    "\n",
    "Usando este método podemos entrenar el modelo de punta a punta y encontrar un mapeo directo de una imagen en escala de grises a una imagen en color.\n",
    "\n",
    "La arquitectura de el modelo es simétrica, con $n$ capas que reducen la entrada y $n$ capas que aumentan los vectores intermedios aprendidos. Sin embargo, existe un cuello de botella en la información que previene el flujo de la información de bajo nivel en la red en este tipo de arquitectura. Para arreglar este problema, las características de la etapa de reducción de la entrada son concatenadas con la capa equivalente en la etapa expansiva.\n",
    "\n",
    "Esto hace que la entrada y salida compartan la ubicación de bordes importanes en escala de grises y colores. Esta arquitectura es llamada **U-net** donde hay conexiones entre la capa $i$ y la capa $n-i$.\n",
    "\n",
    "<img src=\"img/unet.png\">\n",
    "\n",
    "El modelo es entrenado para minimizar la distancia Euclidiana entre la imagen predicha y la real promediando sobre todos los pixeles:\n",
    "\n",
    "$$J(x;\\theta) = \\frac{1}{3n}\\sum^3_{l=1}\\sum^n_{p=1} \\lVert h(x;\\theta)^{(p,l)}-y^{p,l} \\rVert $$\n",
    "\n",
    "donde $x$ es la imagen en grises, $y$ es la imagen a color correspondienta, $p$ y $l$ son el indice del pixel y el canal de color respectivamente, $n$ es el total de pixeles, y $h$ es una función mapeando de escala de grises a color.\n",
    "\n",
    "## GAN Convolucional\n",
    "\n",
    "La arquitectura del generador $G$ es la misma que la red básica anterior. Para el discriminador $D$ usan una arquitectura similar a la parte contractiva en U-net, después de la última capa de convolución se mapea a una salida unidimensional, seguida por una función sigmoide para retornar un valor de probabilidad de que la entrada sea real o false. La entrada al discriminador es una image a color ya sea que venga del generador o de las imágenes reales, concatenada con la imagen a escala de grises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación\n",
    "\n",
    "El readme incluye información detallada para descargar los pesos del entrenamiento sobre Cifar10 y Places365 datasets.\n",
    "\n",
    "A continuación se muestran algunas de las imágenes colorizadas que de ninguna manera pertenecen a los datasets de entrenamiento usando el método propuesto en el artículo.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src='checkpoints/test/foto1.jpg' width=256px></td>\n",
    "        <td><img src='checkpoints/output/foto1.jpg' width=256px></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src='checkpoints/test/foto2.jpg' width=256px></td>\n",
    "        <td><img src='checkpoints/output/foto2.jpg' width=256px></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src='checkpoints/test/foto3.jpg' width=256px></td>\n",
    "        <td><img src='checkpoints/output/foto3.jpg' width=256px></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src='checkpoints/test/foto4.jpg' width=256px></td>\n",
    "        <td><img src='checkpoints/output/foto4.jpg' width=256px></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src='checkpoints/test/foto5.jpg' width=256px></td>\n",
    "        <td><img src='checkpoints/output/foto5.jpg' width=256px></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
